{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nVoice Localizer RSA analysis on a subject\n=========================================\n\nLoad singletrial beta maps of a subject. First half of them correspond to\nvoice stimuli and second half to non-voice stimuli.\nThen compute brain RDMs in the grey matter and finally compare (permutation\ntest) those RDMs with the Voice/Non-voice model RDM.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import os.path as op\nimport nibabel as nb\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom nilearn.image import resample_to_img, concat_imgs\nfrom nilearn import plotting\n\nfrom brainrsa import SearchLightRSA\nfrom brainrsa.plotting import plot_rdm\nfrom brainrsa.utils import check_mask\n\n\n# ******************************************************************************\n# ***** Input parameters *******************************************************\n# ******************************************************************************\n# Number of betas (to load them and also construct the model RDM)\nn_betas = 40\n\n# Will compute brain RDMs only in grey matter\nprocess_mask = \"/hpc/banco/cagna.b/projects/ageing/data/preprocessing/\" + \\\n               \"sub-04/anat/c1sanlm_sub-04_T1w.nii\"\n# Directory of the singletrial GLM\nbeta_dir = \"/hpc/banco/cagna.b/projects/ageing/data/analyses/sub-04/glm/\" + \\\n           \"uasub-04_task-voicelocalizer_model-singletrial\"\n#\u00a0Where the beta value sare actually available\ndata_mask = op.join(beta_dir, \"mask.nii\")\n\n# ******************************************************************************\n# ***** Compute brain RDMs in the ROI ******************************************\n# ******************************************************************************\n# List beta files of the subject\nbeta_imgs = []\nfor b in range(n_betas):\n    beta_imgs.append(op.join(beta_dir, \"beta_{:04d}.nii\".format(b+1)))\n\n#\u00a0Then, load all the images and put them in a new one (4D)\nbeta_imgs = concat_imgs(beta_imgs)\n\n# ******************************************************************************\n# ***** Compute brain RDMs in the ROI ******************************************\n# ******************************************************************************\n# Load the mask and check that it is binary\ndata_mask = check_mask(data_mask, threshold=0.5)\n\n# Resample procmask to match datamask resolution\nprocess_mask = check_mask(\n    resample_to_img(process_mask, data_mask), \n    threshold=0.5\n)\n\n# Initialise the searchlight and specify where to compute the values and the \n# radius of the spege (in milimeters)\nrsa = SearchLightRSA(\n    data_mask,\n    process_mask_img=process_mask,\n    distance='euclidean',\n    radius=6,\n    n_jobs=20,\n    verbose=2\n)\n\n## Compute beta distance matrix (RDMs) for each voxel of the process_mask using\n## voxels included in data_mask\n#print(\"Start to fit brain RDMs\")\n#rdms = rsa.fit(beta_imgs)\n\n## Save the image that give RDM index at each voxel\n## nb.save(rsa.index_image(), indx_map)\n\n## Save RDMs\n## np.save(dist_f, rdms)\n\n## Compute the average RDM\n#avg_rdm = np.mean(rdms, axis=0)\n\n## ******************************************************************************\n## ***** Compare with Voice/Non-Voice model *************************************\n## ******************************************************************************\n## Create the model RDM\n#mid = int(n_betas/2)\n#model = np.zeros((n_betas, n_betas))\n#model[:mid, mid:] = 1\n#model[mid:, :mid] = 1\n\n## Then, do the comparison with each brain RDMs (permuatation test)\n#print('start to compare brain RDMs to model RDM')\n#scores_img = rsa.compare_to(model, distance=\"spearmanr\", n_perms=100)\n\n## Compute just the distance with the model\n##corr_img = rsa.distance_to(squareform(models[im]), distance, True)\n##save_map(corr_img, brain, dist2model_tmpl.replace(\"[m]\", model),\n##         \"Spearman ranked distance to \" + model + \" model\")\n\n## ******************************************************************************\n## ***** Figure *****************************************************************\n## ******************************************************************************\n#fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n\n## Show the mask\n#plotting.plot_roi(process_mask, data_mask, display_mode='x', cut_coords=1, \n#                  axes=axes[0, 0], title=\"Process mask over data mask\")\n\n## The average RDM\n#plot_rdm(avg_rdm, \"Average RDM\", sigtri=\"lower\", ax=axes[0, 1])\n\n## The model\n#plot_rdm(model, \"Voice/Non-voice model\", sigtri=\"lower\", ax=axes[0, 1])\n\n## And the score map\n#plotting.plot_stat_map(\n#    scores_img, display_mode='x', cut_coords=1, colorbar=True, axes=axes[1, 1], \n#    title=\"Comparison to V/NV model\")\n\nplotting.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}